{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ CLEANING: XÃ“A DÃ’NG CSV KHÃ”NG CÃ“ áº¢NH\n",
      "========================================\n",
      "ğŸ” AUTO-DETECTING FILES...\n",
      "ğŸ“„ Found CSV files:\n",
      "   ./age_gender_labels_only.csv (0.9MB)\n",
      "   ./age_gender_labels_only_FINAL_CLEANED.csv (0.3MB)\n",
      "ğŸ“ Found image folders:\n",
      "   ./data/ (10,137 images)\n",
      "\n",
      "ğŸš€ PROCESSING:\n",
      "   CSV: ./age_gender_labels_only.csv\n",
      "   Images: ./data/\n",
      "\n",
      "ğŸ“– CSV: ./age_gender_labels_only.csv\n",
      "ğŸ“ Images: ./data\n",
      "âœ… CSV: 23,705 dÃ²ng\n",
      "âœ… Images: 10,137 files\n",
      "ğŸ“‹ Column: 'img_name'\n",
      "\n",
      "ğŸ“Š RESULTS:\n",
      "   ğŸ“‹ Original: 23,705\n",
      "   âœ… Kept: 0\n",
      "   ğŸ—‘ï¸ Removed: 23,705\n",
      "   ğŸ“ˆ Keep rate: 0.0%\n",
      "ğŸ’¾ Saved: ./age_gender_labels_only_cleaned.csv\n",
      "\n",
      "âœ… SUCCESS!\n",
      "ğŸ¯ Dataset synced: 0 samples\n",
      "ğŸ“ Ready for RGB training!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—‘ï¸ XÃ“A DÃ’NG KHÃ”NG CÃ“ áº¢NH TÆ¯Æ NG á»¨NG\n",
    "print(\"ğŸ—‘ï¸ CLEANING: XÃ“A DÃ’NG CSV KHÃ”NG CÃ“ áº¢NH\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# FUNCTION CHÃNH\n",
    "def clean_labels_remove_orphans(csv_path, images_path):\n",
    "    \"\"\"XÃ³a dÃ²ng CSV khÃ´ng cÃ³ áº£nh tÆ°Æ¡ng á»©ng\"\"\"\n",
    "    print(f\"ğŸ“– CSV: {csv_path}\")\n",
    "    print(f\"ğŸ“ Images: {images_path}\")\n",
    "    \n",
    "    # Check files exist\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âŒ CSV khÃ´ng tá»“n táº¡i: {csv_path}\")\n",
    "        return\n",
    "    if not os.path.exists(images_path):\n",
    "        print(f\"âŒ Folder khÃ´ng tá»“n táº¡i: {images_path}\")\n",
    "        return\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"âœ… CSV: {len(df):,} dÃ²ng\")\n",
    "    \n",
    "    # Get actual images\n",
    "    extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    actual_images = [f for f in os.listdir(images_path) \n",
    "                    if any(f.lower().endswith(ext) for ext in extensions)]\n",
    "    images_set = set(actual_images)\n",
    "    print(f\"âœ… Images: {len(actual_images):,} files\")\n",
    "    \n",
    "    # Find image column\n",
    "    img_col = None\n",
    "    for col in ['img_name', 'image_name', 'filename']:\n",
    "        if col in df.columns:\n",
    "            img_col = col\n",
    "            break\n",
    "    \n",
    "    if not img_col:\n",
    "        print(f\"âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t áº£nh: {list(df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“‹ Column: '{img_col}'\")\n",
    "    \n",
    "    # Filter matching rows\n",
    "    mask = df[img_col].isin(images_set)\n",
    "    cleaned_df = df[mask].copy()\n",
    "    \n",
    "    # Stats\n",
    "    original = len(df)\n",
    "    cleaned = len(cleaned_df)\n",
    "    removed = original - cleaned\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸ“Š RESULTS:\")\n",
    "    print(f\"   ğŸ“‹ Original: {original:,}\")\n",
    "    print(f\"   âœ… Kept: {cleaned:,}\")\n",
    "    print(f\"   ğŸ—‘ï¸ Removed: {removed:,}\")\n",
    "    print(f\"   ğŸ“ˆ Keep rate: {cleaned/original*100:.1f}%\")\n",
    "    \n",
    "    # Save cleaned file\n",
    "    output = csv_path.replace('.csv', '_cleaned.csv')\n",
    "    cleaned_df.to_csv(output, index=False)\n",
    "    print(f\"ğŸ’¾ Saved: {output}\")\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# AUTO-DETECT FILES\n",
    "print(\"ğŸ” AUTO-DETECTING FILES...\")\n",
    "\n",
    "# Find CSV files\n",
    "csv_candidates = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            path = os.path.join(root, file).replace('\\\\', '/')\n",
    "            csv_candidates.append(path)\n",
    "\n",
    "# Find image folders\n",
    "img_candidates = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    img_count = sum(1 for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png')))\n",
    "    if img_count > 0:\n",
    "        path = root.replace('\\\\', '/')\n",
    "        img_candidates.append((path, img_count))\n",
    "\n",
    "print(\"ğŸ“„ Found CSV files:\")\n",
    "for path in csv_candidates:\n",
    "    size = os.path.getsize(path) / 1024 / 1024\n",
    "    print(f\"   {path} ({size:.1f}MB)\")\n",
    "\n",
    "print(\"ğŸ“ Found image folders:\")\n",
    "for path, count in img_candidates:\n",
    "    print(f\"   {path}/ ({count:,} images)\")\n",
    "\n",
    "# Process if found\n",
    "if csv_candidates and img_candidates:\n",
    "    # Pick largest CSV and folder with most images\n",
    "    main_csv = max(csv_candidates, key=os.path.getsize)\n",
    "    main_img = max(img_candidates, key=lambda x: x[1])[0]\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸš€ PROCESSING:\")\n",
    "    print(f\"   CSV: {main_csv}\")\n",
    "    print(f\"   Images: {main_img}/\")\n",
    "    print()\n",
    "    \n",
    "    # Clean the data\n",
    "    result = clean_labels_remove_orphans(main_csv, main_img)\n",
    "    \n",
    "    if result is not None:\n",
    "        print()\n",
    "        print(\"âœ… SUCCESS!\")\n",
    "        print(f\"ğŸ¯ Dataset synced: {len(result):,} samples\")\n",
    "        print(\"ğŸ“ Ready for RGB training!\")\n",
    "        \n",
    "else:\n",
    "    print()\n",
    "    print(\"âŒ Files not found automatically\")\n",
    "    print(\"ğŸ’¡ Manual usage:\")\n",
    "    print(\"clean_labels_remove_orphans('labels.csv', 'images/')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ CLEANING: XÃ“A DÃ’NG CSV KHÃ”NG CÃ“ áº¢NH\n",
      "========================================\n",
      "ğŸ” AUTO-DETECTING FILES...\n",
      "ğŸ“„ Found CSV files:\n",
      "   ./age_gender_labels_only.csv (0.9MB)\n",
      "   ./age_gender_labels_only_cleaned.csv (0.0MB)\n",
      "   ./age_gender_labels_only_FINAL_CLEANED.csv (0.3MB)\n",
      "ğŸ“ Found image folders:\n",
      "   ./data/ (10,137 images)\n",
      "\n",
      "ğŸš€ PROCESSING:\n",
      "   CSV: ./age_gender_labels_only.csv\n",
      "   Images: ./data/\n",
      "\n",
      "ğŸ“– CSV: ./age_gender_labels_only.csv\n",
      "ğŸ“ Images: ./data\n",
      "âœ… CSV: 23,705 dÃ²ng\n",
      "âœ… Images: 10,137 files\n",
      "ğŸ“‹ Column: 'img_name'\n",
      "\n",
      "ğŸ“Š RESULTS:\n",
      "   ğŸ“‹ Original: 23,705\n",
      "   âœ… Kept: 0\n",
      "   ğŸ—‘ï¸ Removed: 23,705\n",
      "   ğŸ“ˆ Keep rate: 0.0%\n",
      "ğŸ’¾ Saved: ./age_gender_labels_only_cleaned.csv\n",
      "\n",
      "âœ… SUCCESS!\n",
      "ğŸ¯ Dataset synced: 0 samples\n",
      "ğŸ“ Ready for RGB training!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—‘ï¸ XÃ“A DÃ’NG KHÃ”NG CÃ“ áº¢NH TÆ¯Æ NG á»¨NG\n",
    "print(\"ğŸ—‘ï¸ CLEANING: XÃ“A DÃ’NG CSV KHÃ”NG CÃ“ áº¢NH\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# FUNCTION CHÃNH\n",
    "def clean_labels_remove_orphans(csv_path, images_path):\n",
    "    \"\"\"XÃ³a dÃ²ng CSV khÃ´ng cÃ³ áº£nh tÆ°Æ¡ng á»©ng\"\"\"\n",
    "    print(f\"ğŸ“– CSV: {csv_path}\")\n",
    "    print(f\"ğŸ“ Images: {images_path}\")\n",
    "    \n",
    "    # Check files exist\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âŒ CSV khÃ´ng tá»“n táº¡i: {csv_path}\")\n",
    "        return\n",
    "    if not os.path.exists(images_path):\n",
    "        print(f\"âŒ Folder khÃ´ng tá»“n táº¡i: {images_path}\")\n",
    "        return\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"âœ… CSV: {len(df):,} dÃ²ng\")\n",
    "    \n",
    "    # Get actual images\n",
    "    extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    actual_images = [f for f in os.listdir(images_path) \n",
    "                    if any(f.lower().endswith(ext) for ext in extensions)]\n",
    "    images_set = set(actual_images)\n",
    "    print(f\"âœ… Images: {len(actual_images):,} files\")\n",
    "    \n",
    "    # Find image column\n",
    "    img_col = None\n",
    "    for col in ['img_name', 'image_name', 'filename']:\n",
    "        if col in df.columns:\n",
    "            img_col = col\n",
    "            break\n",
    "    \n",
    "    if not img_col:\n",
    "        print(f\"âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t áº£nh: {list(df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“‹ Column: '{img_col}'\")\n",
    "    \n",
    "    # Filter matching rows\n",
    "    mask = df[img_col].isin(images_set)\n",
    "    cleaned_df = df[mask].copy()\n",
    "    \n",
    "    # Stats\n",
    "    original = len(df)\n",
    "    cleaned = len(cleaned_df)\n",
    "    removed = original - cleaned\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸ“Š RESULTS:\")\n",
    "    print(f\"   ğŸ“‹ Original: {original:,}\")\n",
    "    print(f\"   âœ… Kept: {cleaned:,}\")\n",
    "    print(f\"   ğŸ—‘ï¸ Removed: {removed:,}\")\n",
    "    print(f\"   ğŸ“ˆ Keep rate: {cleaned/original*100:.1f}%\")\n",
    "    \n",
    "    # Save cleaned file\n",
    "    output = csv_path.replace('.csv', '_cleaned.csv')\n",
    "    cleaned_df.to_csv(output, index=False)\n",
    "    print(f\"ğŸ’¾ Saved: {output}\")\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# AUTO-DETECT FILES\n",
    "print(\"ğŸ” AUTO-DETECTING FILES...\")\n",
    "\n",
    "# Find CSV files\n",
    "csv_candidates = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            path = os.path.join(root, file).replace('\\\\', '/')\n",
    "            csv_candidates.append(path)\n",
    "\n",
    "# Find image folders\n",
    "img_candidates = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    img_count = sum(1 for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png')))\n",
    "    if img_count > 0:\n",
    "        path = root.replace('\\\\', '/')\n",
    "        img_candidates.append((path, img_count))\n",
    "\n",
    "print(\"ğŸ“„ Found CSV files:\")\n",
    "for path in csv_candidates:\n",
    "    size = os.path.getsize(path) / 1024 / 1024\n",
    "    print(f\"   {path} ({size:.1f}MB)\")\n",
    "\n",
    "print(\"ğŸ“ Found image folders:\")\n",
    "for path, count in img_candidates:\n",
    "    print(f\"   {path}/ ({count:,} images)\")\n",
    "\n",
    "# Process if found\n",
    "if csv_candidates and img_candidates:\n",
    "    # Pick largest CSV and folder with most images\n",
    "    main_csv = max(csv_candidates, key=os.path.getsize)\n",
    "    main_img = max(img_candidates, key=lambda x: x[1])[0]\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸš€ PROCESSING:\")\n",
    "    print(f\"   CSV: {main_csv}\")\n",
    "    print(f\"   Images: {main_img}/\")\n",
    "    print()\n",
    "    \n",
    "    # Clean the data\n",
    "    result = clean_labels_remove_orphans(main_csv, main_img)\n",
    "    \n",
    "    if result is not None:\n",
    "        print()\n",
    "        print(\"âœ… SUCCESS!\")\n",
    "        print(f\"ğŸ¯ Dataset synced: {len(result):,} samples\")\n",
    "        print(\"ğŸ“ Ready for RGB training!\")\n",
    "        \n",
    "else:\n",
    "    print()\n",
    "    print(\"âŒ Files not found automatically\")\n",
    "    print(\"ğŸ’¡ Manual usage:\")\n",
    "    print(\"clean_labels_remove_orphans('labels.csv', 'images/')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ FIXED CLEANING SOLUTION\n",
      "===================================\n",
      "ğŸš€ STARTING FIXED CLEANING PROCESS...\n",
      "ğŸ“– Loading: ./age_gender_labels_only.csv\n",
      "âœ… CSV loaded: 23,705 rows\n",
      "   Columns: ['age', 'ethnicity', 'gender', 'img_name']\n",
      "\n",
      "ğŸ“ Scanning folder: ./data\n",
      "âœ… Total files found: 10,137\n",
      "\n",
      "ğŸ” SAMPLE FILES IN FOLDER:\n",
      "   1. 100_1_0_20170110183726390.jpg\n",
      "   2. 100_1_2_20170105174847679.jpg\n",
      "   3. 100_1_2_20170110182836729.jpg\n",
      "   4. 101_1_2_20170105174739309.jpg\n",
      "   5. 10_0_0_20161220222308131.jpg\n",
      "   6. 10_0_0_20170103200329407.jpg\n",
      "   7. 10_0_0_20170103200522151.jpg\n",
      "   8. 10_0_0_20170103233459275.jpg\n",
      "   9. 10_0_0_20170104013211746.jpg\n",
      "   10. 10_0_0_20170110215927291.jpg\n",
      "\n",
      "ğŸ” SAMPLE NAMES IN CSV:\n",
      "   1. 20161219203650636.jpg.chip.jpg\n",
      "   2. 20161219222752047.jpg.chip.jpg\n",
      "   3. 20161219222832191.jpg.chip.jpg\n",
      "   4. 20161220144911423.jpg.chip.jpg\n",
      "   5. 20161220144914327.jpg.chip.jpg\n",
      "   6. 20161220144957407.jpg.chip.jpg\n",
      "   7. 20161220145040127.jpg.chip.jpg\n",
      "   8. 20170109191125532.jpg.chip.jpg\n",
      "   9. 20161219222749039.jpg.chip.jpg\n",
      "   10. 20170109191209991.jpg.chip.jpg\n",
      "\n",
      "ğŸ” CHECKING EXACT MATCHES...\n",
      "\n",
      "ğŸ“Š EXACT MATCH RESULTS:\n",
      "   Total exact matches: 0\n",
      "   Match rate: 0.0%\n",
      "\n",
      "ğŸ” NO EXACT MATCHES - TRYING PARTIAL MATCHING...\n",
      "   CSV timestamps found: 23,474\n",
      "   File timestamps found: 10,065\n",
      "   âœ… TIMESTAMP MATCH: 20161219203650636.jpg.chip.jpg â†’ 1_0_2_20161219203650636.jpg\n",
      "   âœ… TIMESTAMP MATCH: 20161219222752047.jpg.chip.jpg â†’ 1_0_2_20161219222752047.jpg\n",
      "   âœ… TIMESTAMP MATCH: 20161219222832191.jpg.chip.jpg â†’ 1_0_2_20161219222832191.jpg\n",
      "   âœ… TIMESTAMP MATCH: 20161220144911423.jpg.chip.jpg â†’ 1_0_2_20161220144911423.jpg\n",
      "   âœ… TIMESTAMP MATCH: 20161220144914327.jpg.chip.jpg â†’ 1_0_2_20161220144914327.jpg\n",
      "\n",
      "ğŸ“Š TIMESTAMP MATCH RESULTS:\n",
      "   Timestamp matches: 9,707\n",
      "   Match rate: 40.9%\n",
      "\n",
      "ğŸ¯ USING TIMESTAMP MATCHES\n",
      "\n",
      "âœ… CLEANING COMPLETED!\n",
      "ğŸ“‹ Original: 23,705 rows\n",
      "ğŸ“‹ Cleaned: 9,707 rows\n",
      "ğŸ“ˆ Success rate: 40.9%\n",
      "ğŸ’¾ Saved to: ./age_gender_labels_only_FINAL_CLEANED.csv\n",
      "\n",
      "ğŸ” FINAL CLEANED SAMPLE:\n",
      "   âœ… 1_0_2_20161219203650636.jpg\n",
      "   âœ… 1_0_2_20161219222752047.jpg\n",
      "   âœ… 1_0_2_20161219222832191.jpg\n",
      "   âœ… 1_0_2_20161220144911423.jpg\n",
      "   âœ… 1_0_2_20161220144914327.jpg\n",
      "\n",
      "ğŸ‰ SUCCESS! Dataset ready with 9,707 samples!\n",
      "ğŸ“ Use file: age_gender_labels_only_FINAL_CLEANED.csv\n",
      "ğŸš€ Ready for RGB training!\n",
      "\n",
      "ğŸ“‹ NEXT: Use the FINAL_CLEANED.csv file for training!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ FIX CLEANING - Sá»¬A Láº I Tá»ª Äáº¦U\n",
    "print(\"ğŸ”§ FIXED CLEANING SOLUTION\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "def simple_clean_csv(csv_file, data_folder):\n",
    "    \"\"\"Simple vÃ  hiá»‡u quáº£ - xÃ³a dÃ²ng khÃ´ng cÃ³ áº£nh\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ“– Loading: {csv_file}\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"âœ… CSV loaded: {len(df):,} rows\")\n",
    "    print(f\"   Columns: {list(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ Scanning folder: {data_folder}\")\n",
    "    all_files = os.listdir(data_folder)\n",
    "    print(f\"âœ… Total files found: {len(all_files):,}\")\n",
    "    \n",
    "    # Láº¥y 10 sample files Ä‘á»ƒ debug\n",
    "    print(f\"\\nğŸ” SAMPLE FILES IN FOLDER:\")\n",
    "    for i, file in enumerate(all_files[:10]):\n",
    "        print(f\"   {i+1}. {file}\")\n",
    "    \n",
    "    # Láº¥y 10 sample tá»« CSV\n",
    "    print(f\"\\nğŸ” SAMPLE NAMES IN CSV:\")\n",
    "    img_col = 'img_name'\n",
    "    for i, name in enumerate(df[img_col].head(10)):\n",
    "        print(f\"   {i+1}. {name}\")\n",
    "    \n",
    "    # Táº¡o set táº¥t cáº£ files (khÃ´ng filter extension)\n",
    "    files_set = set(all_files)\n",
    "    \n",
    "    # Check exact matches\n",
    "    print(f\"\\nğŸ” CHECKING EXACT MATCHES...\")\n",
    "    exact_matches = []\n",
    "    for idx, row in df.iterrows():\n",
    "        img_name = row[img_col]\n",
    "        if img_name in files_set:\n",
    "            exact_matches.append(idx)\n",
    "            if len(exact_matches) <= 5:  # Show first 5 matches\n",
    "                print(f\"   âœ… MATCH: {img_name}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š EXACT MATCH RESULTS:\")\n",
    "    print(f\"   Total exact matches: {len(exact_matches):,}\")\n",
    "    print(f\"   Match rate: {len(exact_matches)/len(df)*100:.1f}%\")\n",
    "    \n",
    "    if len(exact_matches) == 0:\n",
    "        print(f\"\\nğŸ” NO EXACT MATCHES - TRYING PARTIAL MATCHING...\")\n",
    "        \n",
    "        # Thá»­ partial matching vá»›i timestamp\n",
    "        import re\n",
    "        \n",
    "        # Extract timestamps tá»« CSV\n",
    "        csv_timestamps = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            img_name = row[img_col]\n",
    "            # TÃ¬m timestamp 17 digits\n",
    "            match = re.search(r'(\\d{17})', img_name)\n",
    "            if match:\n",
    "                timestamp = match.group(1)\n",
    "                csv_timestamps[timestamp] = idx\n",
    "        \n",
    "        print(f\"   CSV timestamps found: {len(csv_timestamps):,}\")\n",
    "        \n",
    "        # Extract timestamps tá»« files\n",
    "        file_timestamps = {}\n",
    "        for file in all_files:\n",
    "            match = re.search(r'(\\d{17})', file)\n",
    "            if match:\n",
    "                timestamp = match.group(1)\n",
    "                file_timestamps[timestamp] = file\n",
    "        \n",
    "        print(f\"   File timestamps found: {len(file_timestamps):,}\")\n",
    "        \n",
    "        # Match by timestamp\n",
    "        timestamp_matches = []\n",
    "        mapping = {}\n",
    "        \n",
    "        for timestamp in csv_timestamps:\n",
    "            if timestamp in file_timestamps:\n",
    "                csv_idx = csv_timestamps[timestamp]\n",
    "                actual_file = file_timestamps[timestamp]\n",
    "                timestamp_matches.append(csv_idx)\n",
    "                \n",
    "                # Store mapping for later use\n",
    "                original_name = df.iloc[csv_idx][img_col]\n",
    "                mapping[original_name] = actual_file\n",
    "                \n",
    "                if len(timestamp_matches) <= 5:\n",
    "                    print(f\"   âœ… TIMESTAMP MATCH: {original_name} â†’ {actual_file}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š TIMESTAMP MATCH RESULTS:\")\n",
    "        print(f\"   Timestamp matches: {len(timestamp_matches):,}\")\n",
    "        print(f\"   Match rate: {len(timestamp_matches)/len(df)*100:.1f}%\")\n",
    "        \n",
    "        # Use timestamp matches\n",
    "        if len(timestamp_matches) > 0:\n",
    "            matches_to_use = timestamp_matches\n",
    "            print(f\"\\nğŸ¯ USING TIMESTAMP MATCHES\")\n",
    "            \n",
    "            # Update img_name vá»›i actual filenames\n",
    "            df_copy = df.copy()\n",
    "            for idx in matches_to_use:\n",
    "                original_name = df_copy.iloc[idx][img_col]\n",
    "                if original_name in mapping:\n",
    "                    df_copy.iloc[idx, df_copy.columns.get_loc(img_col)] = mapping[original_name]\n",
    "            \n",
    "            cleaned_df = df_copy.iloc[matches_to_use].copy()\n",
    "        else:\n",
    "            print(f\"âŒ NO MATCHES FOUND AT ALL\")\n",
    "            return None\n",
    "    else:\n",
    "        # Use exact matches\n",
    "        matches_to_use = exact_matches\n",
    "        cleaned_df = df.iloc[matches_to_use].copy()\n",
    "        print(f\"\\nğŸ¯ USING EXACT MATCHES\")\n",
    "    \n",
    "    # Save cleaned dataset\n",
    "    output_file = csv_file.replace('.csv', '_FINAL_CLEANED.csv')\n",
    "    cleaned_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nâœ… CLEANING COMPLETED!\")\n",
    "    print(f\"ğŸ“‹ Original: {len(df):,} rows\")\n",
    "    print(f\"ğŸ“‹ Cleaned: {len(cleaned_df):,} rows\")\n",
    "    print(f\"ğŸ“ˆ Success rate: {len(cleaned_df)/len(df)*100:.1f}%\")\n",
    "    print(f\"ğŸ’¾ Saved to: {output_file}\")\n",
    "    \n",
    "    # Show final sample\n",
    "    print(f\"\\nğŸ” FINAL CLEANED SAMPLE:\")\n",
    "    for name in cleaned_df[img_col].head(5):\n",
    "        print(f\"   âœ… {name}\")\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# RUN THE FIXED CLEANING\n",
    "print(\"ğŸš€ STARTING FIXED CLEANING PROCESS...\")\n",
    "result = simple_clean_csv('./age_gender_labels_only.csv', './data')\n",
    "\n",
    "if result is not None and len(result) > 0:\n",
    "    print(f\"\\nğŸ‰ SUCCESS! Dataset ready with {len(result):,} samples!\")\n",
    "    print(f\"ğŸ“ Use file: age_gender_labels_only_FINAL_CLEANED.csv\")\n",
    "    print(f\"ğŸš€ Ready for RGB training!\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Cleaning failed - need manual investigation\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ NEXT: Use the FINAL_CLEANED.csv file for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ CLEANING CSV - XÃ“A DÃ’NG KHÃ”NG CÃ“ áº¢NH\n",
      "=============================================\n",
      "ğŸš€ Tá»° Äá»˜NG TÃŒM VÃ€ CLEAN DATA...\n",
      "\n",
      "ğŸ“„ CSV files tÃ¬m tháº¥y:\n",
      "   1. ./age_gender_labels_only.csv (0.9MB)\n",
      "   2. ./age_gender_labels_only_cleaned.csv (0.0MB)\n",
      "   3. ./age_gender_labels_only_FINAL_CLEANED.csv (0.3MB)\n",
      "\n",
      "ğŸ“ Image folders tÃ¬m tháº¥y:\n",
      "   1. ./data/ (10,137 áº£nh)\n",
      "\n",
      "ğŸ¯ AUTO-SELECTED:\n",
      "   ğŸ“„ CSV: ./age_gender_labels_only.csv\n",
      "   ğŸ“ Images: ./data/\n",
      "\n",
      "ğŸ“– Äá»c CSV: ./age_gender_labels_only.csv\n",
      "ğŸ“ Kiá»ƒm tra áº£nh trong: ./data\n",
      "\n",
      "âœ… Loaded CSV: 23,705 dÃ²ng\n",
      "   Columns: ['age', 'ethnicity', 'gender', 'img_name']\n",
      "âœ… TÃ¬m tháº¥y: 10,137 áº£nh thá»±c táº¿\n",
      "ğŸ“‹ Sá»­ dá»¥ng cá»™t: 'img_name'\n",
      "\n",
      "ğŸ” Kiá»ƒm tra tá»«ng dÃ²ng...\n",
      "ğŸ“Š Káº¾T QUáº¢:\n",
      "   ğŸ“‹ DÃ²ng gá»‘c: 23,705\n",
      "   âœ… Giá»¯ láº¡i: 0\n",
      "   ğŸ—‘ï¸  ÄÃ£ xÃ³a: 23,705\n",
      "   ğŸ“ˆ Tá»· lá»‡ giá»¯: 0.0%\n",
      "ğŸ’¾ ÄÃ£ lÆ°u file clean: ./age_gender_labels_only_cleaned.csv\n",
      "\n",
      "ğŸ“ˆ PHÃ‚N TÃCH CHI TIáº¾T:\n",
      "-------------------------\n",
      "ğŸ‘¥ Gender distribution:\n",
      "\n",
      "ğŸŒ Ethnicity distribution:\n",
      "\n",
      "ğŸ“… Age statistics:\n",
      "   Min: nan years\n",
      "   Max: nan years\n",
      "   Mean: nan years\n",
      "   Median: nan years\n",
      "\n",
      "ğŸ” Sample cleaned data:\n",
      "Empty DataFrame\n",
      "Columns: [age, ethnicity, gender, img_name]\n",
      "Index: []\n",
      "\n",
      "âœ… HOÃ€N THÃ€NH!\n",
      "ğŸ“ File gá»‘c: ./age_gender_labels_only.csv (23,705 dÃ²ng)\n",
      "ğŸ“ File clean: ./age_gender_labels_only_cleaned.csv (0 dÃ²ng)\n",
      "ğŸ¯ Sáºµn sÃ ng train vá»›i 0 áº£nh cÃ³ mÃ u!\n",
      "\n",
      "ğŸ“‹ NEXT STEPS:\n",
      "1ï¸âƒ£ Kiá»ƒm tra file *_cleaned.csv\n",
      "2ï¸âƒ£ Verify cÃ¹ng sá»‘ lÆ°á»£ng vá»›i folder áº£nh\n",
      "3ï¸âƒ£ Ready Ä‘á»ƒ train RGB model! ğŸ¨\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—‘ï¸ XÃ“A CÃC DÃ’NG KHÃ”NG CÃ“ áº¢NH TÆ¯Æ NG á»¨NG\n",
    "print(\"ğŸ—‘ï¸ CLEANING CSV - XÃ“A DÃ’NG KHÃ”NG CÃ“ áº¢NH\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def clean_csv_remove_missing_images(csv_path, image_folder_path, output_path=None):\n",
    "    \"\"\"\n",
    "    XÃ³a cÃ¡c dÃ²ng trong CSV mÃ  khÃ´ng cÃ³ áº£nh tÆ°Æ¡ng á»©ng\n",
    "    \n",
    "    Args:\n",
    "        csv_path: ÄÆ°á»ng dáº«n file CSV\n",
    "        image_folder_path: ÄÆ°á»ng dáº«n folder chá»©a áº£nh\n",
    "        output_path: File output (tá»± Ä‘á»™ng táº¡o náº¿u None)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ğŸ“– Äá»c CSV: {csv_path}\")\n",
    "    print(f\"ğŸ“ Kiá»ƒm tra áº£nh trong: {image_folder_path}\")\n",
    "    print()\n",
    "    \n",
    "    # 1. Kiá»ƒm tra file tá»“n táº¡i\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âŒ File CSV khÃ´ng tá»“n táº¡i: {csv_path}\")\n",
    "        return None\n",
    "        \n",
    "    if not os.path.exists(image_folder_path):\n",
    "        print(f\"âŒ Folder áº£nh khÃ´ng tá»“n táº¡i: {image_folder_path}\")\n",
    "        return None\n",
    "    \n",
    "    # 2. Äá»c CSV\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"âœ… Loaded CSV: {len(df):,} dÃ²ng\")\n",
    "        print(f\"   Columns: {list(df.columns)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i Ä‘á»c CSV: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 3. Láº¥y danh sÃ¡ch áº£nh thá»±c táº¿\n",
    "    try:\n",
    "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "        actual_images = []\n",
    "        \n",
    "        for file in os.listdir(image_folder_path):\n",
    "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                actual_images.append(file)\n",
    "        \n",
    "        actual_images_set = set(actual_images)\n",
    "        print(f\"âœ… TÃ¬m tháº¥y: {len(actual_images):,} áº£nh thá»±c táº¿\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i Ä‘á»c folder áº£nh: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 4. TÃ¬m cá»™t chá»©a tÃªn áº£nh\n",
    "    img_column = None\n",
    "    possible_columns = ['img_name', 'image_name', 'filename', 'file_name', 'image', 'img']\n",
    "    \n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            img_column = col\n",
    "            break\n",
    "    \n",
    "    if img_column is None:\n",
    "        print(f\"âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t tÃªn áº£nh!\")\n",
    "        print(f\"   CÃ³ sáºµn: {list(df.columns)}\")\n",
    "        print(f\"   TÃ¬m kiáº¿m: {possible_columns}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ğŸ“‹ Sá»­ dá»¥ng cá»™t: '{img_column}'\")\n",
    "    print()\n",
    "    \n",
    "    # 5. Lá»c cÃ¡c dÃ²ng cÃ³ áº£nh tÆ°Æ¡ng á»©ng\n",
    "    print(\"ğŸ” Kiá»ƒm tra tá»«ng dÃ²ng...\")\n",
    "    \n",
    "    indices_to_keep = []\n",
    "    indices_to_remove = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        img_name = str(row[img_column])\n",
    "        \n",
    "        if img_name in actual_images_set:\n",
    "            indices_to_keep.append(idx)\n",
    "        else:\n",
    "            indices_to_remove.append(idx)\n",
    "    \n",
    "    # 6. Táº¡o DataFrame Ä‘Ã£ lá»c\n",
    "    cleaned_df = df.iloc[indices_to_keep].copy()\n",
    "    \n",
    "    # 7. Thá»‘ng kÃª\n",
    "    original_count = len(df)\n",
    "    kept_count = len(cleaned_df)\n",
    "    removed_count = len(indices_to_remove)\n",
    "    \n",
    "    print(\"ğŸ“Š Káº¾T QUáº¢:\")\n",
    "    print(f\"   ğŸ“‹ DÃ²ng gá»‘c: {original_count:,}\")\n",
    "    print(f\"   âœ… Giá»¯ láº¡i: {kept_count:,}\")\n",
    "    print(f\"   ğŸ—‘ï¸  ÄÃ£ xÃ³a: {removed_count:,}\")\n",
    "    print(f\"   ğŸ“ˆ Tá»· lá»‡ giá»¯: {kept_count/original_count*100:.1f}%\")\n",
    "    \n",
    "    # 8. LÆ°u file Ä‘Ã£ clean\n",
    "    if output_path is None:\n",
    "        output_path = csv_path.replace('.csv', '_cleaned.csv')\n",
    "    \n",
    "    try:\n",
    "        cleaned_df.to_csv(output_path, index=False)\n",
    "        print(f\"ğŸ’¾ ÄÃ£ lÆ°u file clean: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i lÆ°u file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 9. Hiá»ƒn thá»‹ thá»‘ng kÃª chi tiáº¿t\n",
    "    print()\n",
    "    print(\"ğŸ“ˆ PHÃ‚N TÃCH CHI TIáº¾T:\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    if 'gender' in cleaned_df.columns:\n",
    "        print(\"ğŸ‘¥ Gender distribution:\")\n",
    "        gender_counts = cleaned_df['gender'].value_counts()\n",
    "        for gender, count in gender_counts.items():\n",
    "            gender_name = 'Male' if gender == 0 else 'Female' if gender == 1 else f'Gender_{gender}'\n",
    "            print(f\"   {gender_name}: {count:,} ({count/len(cleaned_df)*100:.1f}%)\")\n",
    "    \n",
    "    if 'ethnicity' in cleaned_df.columns:\n",
    "        print()\n",
    "        print(\"ğŸŒ Ethnicity distribution:\")\n",
    "        ethnicity_counts = cleaned_df['ethnicity'].value_counts()\n",
    "        for eth, count in ethnicity_counts.items():\n",
    "            print(f\"   Ethnicity {eth}: {count:,} ({count/len(cleaned_df)*100:.1f}%)\")\n",
    "    \n",
    "    if 'age' in cleaned_df.columns:\n",
    "        print()\n",
    "        print(\"ğŸ“… Age statistics:\")\n",
    "        print(f\"   Min: {cleaned_df['age'].min()} years\")\n",
    "        print(f\"   Max: {cleaned_df['age'].max()} years\")\n",
    "        print(f\"   Mean: {cleaned_df['age'].mean():.1f} years\")\n",
    "        print(f\"   Median: {cleaned_df['age'].median():.1f} years\")\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸ” Sample cleaned data:\")\n",
    "    print(cleaned_df.head())\n",
    "    \n",
    "    print()\n",
    "    print(\"âœ… HOÃ€N THÃ€NH!\")\n",
    "    print(f\"ğŸ“ File gá»‘c: {csv_path} ({original_count:,} dÃ²ng)\")\n",
    "    print(f\"ğŸ“ File clean: {output_path} ({kept_count:,} dÃ²ng)\")\n",
    "    print(f\"ğŸ¯ Sáºµn sÃ ng train vá»›i {kept_count:,} áº£nh cÃ³ mÃ u!\")\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# AUTO-DETECT VÃ€ THá»°C HIá»†N CLEANING\n",
    "print(\"ğŸš€ Tá»° Äá»˜NG TÃŒM VÃ€ CLEAN DATA...\")\n",
    "print()\n",
    "\n",
    "# TÃ¬m file CSV\n",
    "csv_files = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            path = os.path.join(root, file).replace('\\\\', '/')\n",
    "            csv_files.append(path)\n",
    "\n",
    "# TÃ¬m folder áº£nh  \n",
    "image_folders = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    image_count = sum(1 for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')))\n",
    "    if image_count > 0:\n",
    "        path = root.replace('\\\\', '/')\n",
    "        image_folders.append((path, image_count))\n",
    "\n",
    "print(\"ğŸ“„ CSV files tÃ¬m tháº¥y:\")\n",
    "for i, path in enumerate(csv_files, 1):\n",
    "    try:\n",
    "        size = os.path.getsize(path) / 1024 / 1024\n",
    "        print(f\"   {i}. {path} ({size:.1f}MB)\")\n",
    "    except:\n",
    "        print(f\"   {i}. {path}\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“ Image folders tÃ¬m tháº¥y:\")\n",
    "for i, (path, count) in enumerate(image_folders, 1):\n",
    "    print(f\"   {i}. {path}/ ({count:,} áº£nh)\")\n",
    "\n",
    "# Thá»±c hiá»‡n cleaning tá»± Ä‘á»™ng náº¿u tÃ¬m tháº¥y\n",
    "if csv_files and image_folders:\n",
    "    # Chá»n file CSV lá»›n nháº¥t (cÃ³ thá»ƒ lÃ  file chÃ­nh)\n",
    "    main_csv = max(csv_files, key=lambda x: os.path.getsize(x))\n",
    "    \n",
    "    # Chá»n folder cÃ³ nhiá»u áº£nh nháº¥t\n",
    "    main_folder = max(image_folders, key=lambda x: x[1])[0]\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸ¯ AUTO-SELECTED:\")\n",
    "    print(f\"   ğŸ“„ CSV: {main_csv}\")\n",
    "    print(f\"   ğŸ“ Images: {main_folder}/\")\n",
    "    print()\n",
    "    \n",
    "    # Thá»±c hiá»‡n cleaning\n",
    "    result = clean_csv_remove_missing_images(main_csv, main_folder)\n",
    "    \n",
    "else:\n",
    "    print()\n",
    "    print(\"âŒ KhÃ´ng tÃ¬m tháº¥y Ä‘á»§ files Ä‘á»ƒ auto-process\")\n",
    "    print(\"ğŸ’¡ Sá»­ dá»¥ng manual:\")\n",
    "    print(\"   clean_csv_remove_missing_images('path/to/labels.csv', 'path/to/images/')\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ“‹ NEXT STEPS:\")\n",
    "print(\"1ï¸âƒ£ Kiá»ƒm tra file *_cleaned.csv\")\n",
    "print(\"2ï¸âƒ£ Verify cÃ¹ng sá»‘ lÆ°á»£ng vá»›i folder áº£nh\")\n",
    "print(\"3ï¸âƒ£ Ready Ä‘á»ƒ train RGB model! ğŸ¨\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
